TED-Gen

Official Repository for the paper Auto-resolving atomic structure at van der Waal interfaces using a generative model.
==================================================

Shortcuts
---------

- [TED-Gen](./train/)
- [Modified DRIT](./Modified-DRIT/)
- [Generate simulation data by Computem](./Computem_Gen/)


**Note**: if you want to install or run our codes, please `cd` to subfolders first.


Auto-resolving atomic structure at van der Waal interfaces using a generative model
-------------------------------------------------------------------

[[Paper](https://github.com/dptech-corp/TED-Gen)]

Authors: Wenqiang Huang, Yuchen Jin, Zhemin Li, Lin Yao*, Yun Chen, Zheng Luo, Shen Zhou, Hongxia Wang, Jinguo Lin, Feng Liu, Zhifeng Gao, Jun Cheng, Linfeng Zhang, Fangping Ouyang*, Shanshan Wang* & Jin Zhang 

<p align="center"><img src="image/img01.png" width=60%></p>
<p align="center"><b>ML workflow of the atomic structure inference at van der Waal interfaces</b></p>

Unveiling atomic structures is significant for the relationship construction between microscopic configurations and macroscopic properties of materials.  However, we still lack a rapid, accurate, and robust approach to automatically resolve complex patterns in atomic-resolution microscopy.  Here, we present a Trident strategy-enhanced disentangled representation learning method (a generative model), which utilizes a few unlabeled experimental images with abundant low-cost simulated images to generate a large corpus of annotated simulation data that closely resembles experimental conditions, realizing simultaneous achievement of high quality and large volumes of the training dataset.  A structural inference model is then trained via a residual neural network which can directly deduce the interlayer slip and rotation of diversified and complicated stacking patterns at van der Waals (vdWs) interfaces with picometer-scale accuracy across various materials (ReS2, ReSe2, and MoS2) with different layer numbers (bilayer and trilayers) and demonstrates robustness to defects, imaging quality, and surface contaminations.  The framework can also identify pattern transition interfaces, quantify subtle motif variations, and discriminate moir√© patterns that are undistinguishable in frequency domains.  The high-throughput processing ability of our method helps discover a novel vdW epitaxy where various thermodynamically favorable slip stackings can coexist, demonstrating the machine learning contribution to the new knowledge emergence.

## Usage

Install
--------------------------------------------------------------------
- Clone this repo:
```
git clone https://github.com/dptech-corp/TED-Gen.git
cd code
```

Download datasets
--------------------------------------------------------------------
Dataset of training Modified-DRIT and Stacking-Pattern-Analyzer is available at https://xxxxx

Generate datasets
--------------------------------------------------------------------
You can also use the code we provide to generate simulated STEM images with or without noise.

### Generate noise-free simulated stem images
Simulated STEM images were generated by the open-source 'incoSTEM' package in Computem. These images can be generated for any material and stacking pattern based on predefined structure files.

You can generate an image with label by running the ipynb file in this [subfolder](./Computem_Gen/).

You can also go to [this page](https://sourceforge.net/projects/computem/) to obtain computem software with GUI.

Check this [subfolder](./Computem_Gen/) for more detalis.

### Generate realistic stem images with Modified-DRIT
You can convert the noise-free stem images into realistic stem images using the [Modified-DRIT](./Modified-DRIT/) model we provide.

Before you start [training](./Modified-DRIT/src/train.py) or [generating](./Modified-DRIT/src/test_transfer.py), download the necessary model parameter files and datasets and configure them in the [option.py](./Modified-DRIT/src/options.py) file.

Check this [subfolder](./Modified-DRIT/) for more detalis.

Stacking Pattern Analyzer
--------------------------------------------------------------------
Once the dataset is ready, you can train a stacking pattern analysis model based on the code we provide. Alternatively, you can parse your material using existing model parameters.

Check this [subfolder](./Stacking-Pattern-Analyzer/) for more detalis.

### Training Examples

```
python train.py --dataroot ../datasets/ --task slip
```

### Testing Examples

```
python infer.py --image_path ../datasets/1.png --task slip --weight_path ../model.pth
```

Citation
--------

License
--------
