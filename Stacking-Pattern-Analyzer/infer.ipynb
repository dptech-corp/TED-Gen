{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReS2 Slip Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Da:  1.88    Db:  1.07\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.models as models\n",
    "from model import StructNet\n",
    "import numpy as np\n",
    "from math import cos, sin, tan,degrees, radians\n",
    "from shift_trans import shift_trans\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Model parameter path\n",
    "weight_path = './model/res2_bs.pth'\n",
    "# Image path\n",
    "image_path = './sample_data/1.png' # 2.png 3.png 4.png\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = StructNet(output_dim = 3)\n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(weight_path))\n",
    "model.eval()\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = image.resize((1024,1024))\n",
    "# image = TF.hflip(image)\n",
    "image_list = []\n",
    "\n",
    "for i in range(16):\n",
    "    crop_size = 512 + i * 10\n",
    "    image_c = TF.crop(image, 0, 0, crop_size, crop_size)\n",
    "    image_c = image_c.resize([512,512])\n",
    "    data = TF.to_tensor(image_c)\n",
    "    image_list.append(data)\n",
    "\n",
    "data = torch.stack(image_list,dim = 0).to(device)\n",
    "model_outputs = model(data).detach().cpu().numpy()\n",
    "k_model = KMeans(n_clusters=5)\n",
    "k_model.fit(model_outputs)\n",
    "kmeans_results = k_model.predict(model_outputs)\n",
    "choose_id = np.argmax(np.bincount(kmeans_results))\n",
    "model_outputs = model_outputs[kmeans_results == choose_id]\n",
    "output = model_outputs[:2].mean(axis = 0)\n",
    "d = shift_trans(output[0], output[1])\n",
    "\n",
    "print('Da:  '+'%.2f'% d[1]+'    Db:  '+'%.2f'% d[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReSe2 Slip Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Da:  1.02    Db:  5.22\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.models as models\n",
    "from model import StructNet\n",
    "import numpy as np\n",
    "from math import cos, sin, tan,degrees, radians\n",
    "from shift_trans import shift_trans\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Model parameter path\n",
    "weight_path = './model/rese2_bs.pth'\n",
    "# Image path\n",
    "image_path = './sample_data/ReSe_shift.png'\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = StructNet(output_dim = 2)\n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(weight_path))\n",
    "model.eval()\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = image.resize((1024,1024))\n",
    "# image = TF.hflip(image)\n",
    "image_list = []\n",
    "\n",
    "for i in range(16):\n",
    "    crop_size = 512 + i * 10\n",
    "    image_c = TF.crop(image, 0, 0, crop_size, crop_size)\n",
    "    image_c = image_c.resize([512,512])\n",
    "    data = TF.to_tensor(image_c)\n",
    "    image_list.append(data)\n",
    "\n",
    "data = torch.stack(image_list,dim = 0).to(device)\n",
    "model_outputs = model(data).detach().cpu().numpy()\n",
    "k_model = KMeans(n_clusters=5)\n",
    "k_model.fit(model_outputs)\n",
    "kmeans_results = k_model.predict(model_outputs)\n",
    "choose_id = np.argmax(np.bincount(kmeans_results))\n",
    "model_outputs = model_outputs[kmeans_results == choose_id]\n",
    "output = model_outputs[:2].mean(axis = 0)\n",
    "\n",
    "d = shift_trans(output[0], output[1])\n",
    "print('Da:  '+'%.2f'% d[1]+'    Db:  '+'%.2f'% d[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReS2 3layer Slip Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1 Da:  3.38    Db:  0.39\n",
      "layer2 Da:  4.90    Db:  1.45\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.models as models\n",
    "from model import StructNet\n",
    "import numpy as np\n",
    "from math import cos, sin, tan,degrees, radians\n",
    "from shift_trans import shift_trans\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Model parameter path\n",
    "weight_path = './model/res2_ts.pth'\n",
    "# Image path\n",
    "image_path = './sample_data/ReS2_3layer_shift.png'\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = StructNet(output_dim = 4)\n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(weight_path))\n",
    "model.eval()\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = image.resize((1024,1024))\n",
    "# image = TF.hflip(image)\n",
    "image_list = []\n",
    "\n",
    "for i in range(16):\n",
    "    crop_size = 512 + i * 10\n",
    "    image_c = TF.crop(image, 0, 0, crop_size, crop_size)\n",
    "    image_c = image_c.resize([512,512])\n",
    "    data = TF.to_tensor(image_c)\n",
    "    image_list.append(data)\n",
    "\n",
    "data = torch.stack(image_list,dim = 0).to(device)\n",
    "model_outputs = model(data).detach().cpu().numpy()\n",
    "k_model = KMeans(n_clusters=5)\n",
    "k_model.fit(model_outputs)\n",
    "kmeans_results = k_model.predict(model_outputs)\n",
    "choose_id = np.argmax(np.bincount(kmeans_results))\n",
    "model_outputs = model_outputs[kmeans_results == choose_id]\n",
    "output = model_outputs[:4].mean(axis = 0)\n",
    "d = shift_trans(output[0], output[1])\n",
    "print('layer1 Da:  '+'%.2f'% d[1]+'    Db:  '+'%.2f'% d[0])\n",
    "d = shift_trans(output[2], output[3])\n",
    "print('layer2 Da:  '+'%.2f'% d[1]+'    Db:  '+'%.2f'% d[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MoS2 Twist angel Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twist Angel:  19.66\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.models as models\n",
    "from model import StructNet\n",
    "import numpy as np\n",
    "from math import cos, sin, tan,degrees, radians\n",
    "from shift_trans import shift_trans\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Model parameter path\n",
    "weight_path = './model/mos2_rsub.pth'\n",
    "# Image path\n",
    "image_path = './sample_data/MoS2_rotate.png'\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = StructNet(output_dim = 1)\n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(weight_path))\n",
    "model.eval()\n",
    "\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "image = image.resize((1024,1024))\n",
    "# image = TF.hflip(image)\n",
    "image_list = []\n",
    "\n",
    "for i in range(16):\n",
    "    crop_size = 512 + i * 10\n",
    "    image_c = TF.crop(image, 0, 0, crop_size, crop_size)\n",
    "    image_c = image_c.resize([512,512])\n",
    "    data = TF.to_tensor(image_c)\n",
    "    image_list.append(data)\n",
    "\n",
    "data = torch.stack(image_list,dim = 0).to(device)\n",
    "model_outputs = model(data).detach().cpu().numpy()\n",
    "k_model = KMeans(n_clusters=5)\n",
    "k_model.fit(model_outputs)\n",
    "kmeans_results = k_model.predict(model_outputs)\n",
    "choose_id = np.argmax(np.bincount(kmeans_results))\n",
    "model_outputs = model_outputs[kmeans_results == choose_id]\n",
    "output = model_outputs.mean(axis = 0)*60.0\n",
    "\n",
    "print('Twist Angel:  '+'%.2f'% output[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
